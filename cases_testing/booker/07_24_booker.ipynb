{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test using BlackstoneNLP\n",
    "\n",
    "#import standard library modules\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "#modules from the community\n",
    "import spacy\n",
    "from dataclasses import dataclass #backported this module from 3.7\n",
    "import en_core_web_sm\n",
    "\n",
    "from spacy import displacy\n",
    "from blackstone.displacy_palette import ner_displacy_options\n",
    "\n",
    "from blackstone.pipeline.sentence_segmenter import SentenceSegmenter\n",
    "from blackstone.rules import CITATION_PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_blackstone_proto') #the blackstone model\n",
    "nlp2 = en_core_web_sm.load()\n",
    "#load sentence segmenter\n",
    "sentence_segmenter = SentenceSegmenter(nlp.vocab, CITATION_PATTERNS)\n",
    "nlp.add_pipe(sentence_segmenter, before=\"parser\")\n",
    "\n",
    "#nlp=spacy.load('en_core_web_sm') #the default spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the text into a variable from the .txt file\n",
    "def text_from_file(filename: str) -> str:\n",
    "    with open(filename, 'r') as in_file:\n",
    "        data = in_file.read()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: we still need to load the doc into a model\n",
    "\n",
    "def text_from_json(filename: str, dict_value: str) -> str:\n",
    "    with open(filename, 'r') as in_file:\n",
    "        data=json.load(in_file)\n",
    "        data=data[dict_value]\n",
    "        return data\n",
    "    \n",
    "#NOTE: we don't use this function until later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "booker_string = text_from_file('booker2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's start the model\n",
    "bx = nlp(booker_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In the section above we can see the law's text displayed using displaCy. We have highlighted the cases, provisions, laws, etc in the text.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_casename_citations_filtered(doc)\n",
    "def get_casename_citations_filtered(doc):\n",
    "    #one\n",
    "    '''Takes a spacy doc object and returns a dictionary of cases using the blackstone nlp model\n",
    "    args:\n",
    "        doc: the spacy doc object\n",
    "    returns:\n",
    "        \n",
    "    '''\n",
    "    cases = (i for i in doc.ents if i.label_ == 'CASENAME')\n",
    "    actual_cases=[]\n",
    "    results = {case.text:[item for item in case] for case in cases}\n",
    "    return results\n",
    "\n",
    "def get_actual_cases(case_list: dict) -> List:\n",
    "    '''Takes the cases and removes some of the ones that are not cases\n",
    "    like the ones without a v in them'''\n",
    "    actual_cases = []\n",
    "    for k, v in case_list.items():\n",
    "        for i in v:\n",
    "            if i.text == 'v.' and i.pos_ == 'ADP' and i.dep_ == 'prep':\n",
    "            #if i.pos_ == 'ADP' and i.dep_ == 'prep':\n",
    "                actual_cases.append(k)\n",
    "    return actual_cases\n",
    "\n",
    "def get_cases_from_doc(doc):\n",
    "    return get_actual_cases(get_casename_citations_filtered(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_one = get_cases_from_doc(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_case_text(case_list: List[str]) -> List[str]:\n",
    "    '''Takes a list of cases and removes the newline characters at the end'''\n",
    "    clean_cases = (str(i) for i in case_list)\n",
    "    clean_cases = (i.rstrip('\\n') for i in case_list)\n",
    "    return clean_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blakely v. Washington', 'Mistretta v. United States,', 'Griffith v. Kentucky', 'Mistretta v. United States', 'Stinson v. United States,', 'McMillan v. Pennsylvania', 'Witte v. United States,', '\" United States v. Watts', 'Edwards v. United States,', 'Welsh v. United States', 'Califano v. Westcott', 'Sloan v. Lemon', 'United States v. Watts', 'Koon v. United States', 'United States v. Tsosie', 'United States v. Salinas', 'United States v. Cook', 'United States v. Olabanji', 'Harper v. Virginia Dept.', 'El Paso & Northeastern R. Co. v. Gutierrez', 'Hearings on Blakely v. Washington', 'Patton v. United States', '\" Barrows v. Jackson', '\" United States v. Raines', 'Marbury v. Madison', 'Rust v. Sullivan', '\" Sloan v. Lemon', 'CompareChicago v. Morales', 'Webster v. Reproductive Health Services', 'NLRB v. Jones & Laughlin Steel Corp.,', 'Sixth Amendment violationGriffith v. Kentucky', 'Koon v. United States,', 'Renne v. Geary', 'Tennessee v. Garner', 'CfStinson v. United States,', 'Williams v. United States,', 'SeeReno v. Flores', 'Harris v. United States,', 'Monge v. California', 'Almendarez-Torres v. United States', 'United States v. Pineiro', 'United States v. Penaranda', 'State v. Gore']\n"
     ]
    }
   ],
   "source": [
    "result_one = list(clean_case_text(result_one))\n",
    "print(result_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bx)\n",
    "#displacy.render(bx, style='ent', options=ner_displacy_options)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we've gotten the cases, let's view the document in displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#judges = [i for i in get_judges(bx, doc)]\n",
    "#for i in judges:\n",
    "#    for j in i:\n",
    "#        print(i.text, [j.text for j in i], end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_statutes(case_list: List):\n",
    "    '''removes statutes, each of which have a numeric elemnt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to get the cases\n",
    "#get_actual_cases(get_casename_citations_filtered(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a = ''\n",
    "#dir(a.ljust(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_found = get_cases_from_doc(doc)\n",
    "print('Cases found: ', [(i, i.label_) for i in cases_found])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dir(spacy.tokens.Token))\n",
    "#for i in cases_found:\n",
    "#    for token in i:\n",
    "#        print(token.text, token.pos_, token.dep_, [i for i in token.lefts], [i for i in token.rights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CaseWithNLP:\n",
    "    case_name: str\n",
    "    name_token: spacy.tokens.Token\n",
    "    plaintiff: spacy.tokens.Token\n",
    "    respondant: spacy.tokens.Token\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_case_list(doc):\n",
    "    result = get_cases_from_doc(doc)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[United States v. Standard Oil Co., Dalehite v. United States,]\n"
     ]
    }
   ],
   "source": [
    "res = make_case_with_nlp(doc)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
